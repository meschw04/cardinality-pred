{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import hashlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 ['b', 'd', 'e', 'f', 'g', 'h', 'n', 'w', 'x', 'y', 'z']\n",
      "14 ['a', 'b', 'd', 'f', 'g', 'h', 'k', 'l', 'n', 't', 'u', 'v', 'x', 'z']\n",
      "14 ['a', 'b', 'd', 'i', 'k', 'l', 'n', 'o', 'q', 'r', 's', 'v', 'w', 'x']\n",
      "14 ['a', 'c', 'd', 'e', 'f', 'j', 'l', 'm', 'q', 'r', 's', 't', 'w', 'x']\n",
      "8 ['a', 'b', 'i', 'm', 'q', 't', 'x', 'y']\n"
     ]
    }
   ],
   "source": [
    "#TEMPORARY TEST OF CLASS!\n",
    "attributes = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n',\\\n",
    "              'o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "#Build data for each attribute, start by picking either Normal or U dists\n",
    "dist_select = np.random.choice([0,1],len(attributes))\n",
    "\n",
    "all_data = []\n",
    "data_points_count = 10**3\n",
    "for i in dist_select:\n",
    "    if i: #Use a Gaussian distribution\n",
    "        mean = np.random.uniform(-100,100,1)[0]\n",
    "        stdev = np.random.uniform(10,50,1)[0]\n",
    "        all_data.append(np.random.normal(mean,stdev,data_points_count))\n",
    "    else:\n",
    "        bounds = np.random.uniform(-1000,1000,2)\n",
    "        lower = min(bounds)\n",
    "        upper = max(bounds)\n",
    "        all_data.append(np.random.uniform(lower,upper,data_points_count))\n",
    "\n",
    "full_df = pd.DataFrame(np.array(all_data).T,columns=attributes)\n",
    "#full_df.describe()\n",
    "\n",
    "table_attrs = []\n",
    "num_tables = 5\n",
    "tables_dict = {}\n",
    "for i in range(num_tables):\n",
    "    #Pick random number of attrs in table\n",
    "    num_attrs = np.random.choice(range(6,16),1)[0]\n",
    "    selected_attrs = sorted(np.random.choice(attributes,num_attrs,replace=False))\n",
    "    print(num_attrs,selected_attrs)\n",
    "    table_attrs.append(selected_attrs)\n",
    "    tables_dict[i]=full_df[selected_attrs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tables_dict[0].copy()\n",
    "t['aa']=np.random.choice(range(1,11),len(t))\n",
    "t['bb']=[True]*len(t)\n",
    "t['cc']=[str('test')]*len(t)\n",
    "t['dd']=[str('test2')]*len(t)\n",
    "tables_dict[0]=t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_table_attrs(table_dict):\n",
    "    return np.array(sorted(list(table_dict.keys()))),np.zeros(len(table_dict))\n",
    "    \n",
    "def all_join_attrs(table_dict):\n",
    "    join_li = []\n",
    "    len_join_enc = 0\n",
    "    t_li = sorted(table_dict.keys())\n",
    "    for i in range(len(table_dict)):\n",
    "        for j in range(len(table_dict)):\n",
    "            if i<j:\n",
    "                intersect = sorted([k for k in table_dict[t_li[i]].columns.tolist() \\\n",
    "                             if k in table_dict[t_li[j]].columns.tolist()])\n",
    "                for s in intersect:\n",
    "                    join_li.append(f'join-attr-{t_li[i]}.{s}-to-{t_li[j]}.{s}')\n",
    "                len_join_enc += len(intersect)\n",
    "    join_enc = np.zeros(len(join_li))\n",
    "    return np.array(join_li), join_enc\n",
    "    \n",
    "def all_num_predicate_attrs(table_dict):\n",
    "    num_attrs_li = []\n",
    "    num_attrs_types = []\n",
    "    for i in table_dict.keys():\n",
    "        sub_attrs_li=table_dict[i].columns.tolist()\n",
    "        sub_attrs_types=table_dict[i].dtypes.tolist()\n",
    "        for j in range(len(sub_attrs_li)):\n",
    "            poss_el = f'{i}.{sub_attrs_li[j]}'\n",
    "            if poss_el not in num_attrs_li: #Check if already present\n",
    "                if sub_attrs_types[j].char=='?': #BOOL\n",
    "                    num_attrs_li.append(poss_el)\n",
    "                    num_attrs_types.append(sub_attrs_types[j])\n",
    "                elif sub_attrs_types[j].char=='l': #INT\n",
    "                    num_attrs_li.append(poss_el)\n",
    "                    num_attrs_types.append(sub_attrs_types[j])\n",
    "                elif sub_attrs_types[j].char=='d': #FLOAT\n",
    "                    num_attrs_li.append(poss_el)\n",
    "                    num_attrs_types.append(sub_attrs_types[j])\n",
    "    num_attrs_li+=['<','>','=','NORMALIZED_NUM']\n",
    "    num_attrs_types+=[0,0,0,0]\n",
    "    num_attrs_enc = np.zeros(len(num_attrs_li))\n",
    "    return np.array(num_attrs_li), np.array(num_attrs_types), num_attrs_enc\n",
    "\n",
    "def all_non_num_predicate_attrs(table_dict):\n",
    "    num_attrs_li = []\n",
    "    num_attrs_types = []\n",
    "    for i in table_dict.keys():\n",
    "        sub_attrs_li=table_dict[i].columns.tolist()\n",
    "        sub_attrs_types=table_dict[i].dtypes.tolist()\n",
    "        for j in range(len(sub_attrs_li)):\n",
    "            poss_el = f'{i}.{sub_attrs_li[j]}'\n",
    "            if poss_el not in num_attrs_li: #Check if already present\n",
    "                if sub_attrs_types[j].char=='O': #STRING OBJECT\n",
    "                    num_attrs_li.append(poss_el)\n",
    "                    num_attrs_types.append(sub_attrs_types[j])\n",
    "    num_attrs_li+=['HASHED_INT','E_BALL']\n",
    "    num_attrs_types+=[0,0]\n",
    "    num_attrs_enc = np.zeros(len(num_attrs_li))\n",
    "    return np.array(num_attrs_li), np.array(num_attrs_types), num_attrs_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_select_joins(join_attrs_li,num_joins):\n",
    "    joins_select = np.random.choice(range(len(join_attrs_li)),1).tolist()\n",
    "    valid_tables = []\n",
    "    while len(joins_select)!=num_joins:\n",
    "        t = join_attrs_li[joins_select[-1]].split('.')\n",
    "        table_1 = t[0].replace('join-attr-','')\n",
    "        table_2 = t[1].split('-')[-1]\n",
    "        valid_tables+=[table_1,table_2]\n",
    "\n",
    "        curr_len = len(joins_select)\n",
    "        inds = list(range(len(join_attrs_li)))\n",
    "        random.shuffle(inds)\n",
    "        for i in inds:\n",
    "            if i not in joins_select:\n",
    "                t2 = join_attrs_li[i].split('.')\n",
    "                table_A = t2[0].replace('join-attr-','')\n",
    "                table_B = t2[1].split('-')[-1]\n",
    "                tA=(table_A in valid_tables)\n",
    "                tB=(table_B in valid_tables)\n",
    "                if tA or tB:\n",
    "                    joins_select.append(i)\n",
    "                    break\n",
    "        if len(joins_select)==curr_len:\n",
    "            return []\n",
    "    return joins_select\n",
    "\n",
    "def str_hash_procedure(string):\n",
    "    return float(int(hashlib.sha1(string.encode(\"utf-8\"\\\n",
    "                    )).hexdigest(), 16) % (10 ** 8))/(10**8)\n",
    "\n",
    "def str_L1_distance(str_embedding_1, str_embedding_2):\n",
    "    return abs(str_embedding_1 - str_embedding_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Card_Dataset:\n",
    "    def __init__(self, join_lim=4, num_predicate_lim=4, non_num_predicate_lim=2,\\\n",
    "                 string_embedding=str_hash_procedure,string_dist_func=str_L1_distance):\n",
    "        self.join_lim = join_lim\n",
    "        self.num_predicate_lim = num_predicate_lim\n",
    "        self.non_num_predicate_lim = non_num_predicate_lim\n",
    "        self.string_embedding = string_embedding\n",
    "        self.string_dist_func = string_dist_func\n",
    "        self.table_dict = {}\n",
    "    \n",
    "    def add_table(self,table,name=None):\n",
    "        if name is None:\n",
    "            name = str(int(np.random.choice(range(10**6),1)[0]))\n",
    "        self.table_dict[name]=table\n",
    "    \n",
    "    def featurize_space(self,verbose=False):\n",
    "        #TABLE ATTRS\n",
    "        try:\n",
    "            self.table_attrs_li, self.table_attrs_enc = \\\n",
    "                        all_table_attrs(self.table_dict)\n",
    "        except Exception as e:\n",
    "            raise Exception(f'Failed During Table Parsing:\\n{e}')\n",
    "        if verbose:\n",
    "            print('All Table Names:')\n",
    "            print(self.table_attrs_li)\n",
    "            print('')\n",
    "        \n",
    "        #JOIN ATTRS\n",
    "        try:\n",
    "            self.join_attrs_li, self.join_attrs_enc = \\\n",
    "                            all_join_attrs(self.table_dict)\n",
    "        except Exception as e:\n",
    "            raise Exception(f'Failed During Join Parsing:\\n{e}')\n",
    "        if verbose:\n",
    "            print('All Enumerated Joins:')\n",
    "            print(self.join_attrs_li)\n",
    "            print('')\n",
    "        \n",
    "        #NUMERICAL PREDICATE ATTRS\n",
    "        try:\n",
    "            self.num_preds_li, self.num_preds_type, self.num_preds_enc = \\\n",
    "                            all_num_predicate_attrs(self.table_dict)\n",
    "        except Exception as e:\n",
    "            raise Exception(f'Failed During Numerical Predicate Parsing:\\n{e}')\n",
    "        if verbose:\n",
    "            print('Numerical Predicate Space:')\n",
    "            print(self.num_preds_li)\n",
    "            print('')\n",
    "        \n",
    "        #NON-NUMERICAL PREDICATE ATTRS\n",
    "        try:\n",
    "            self.non_num_preds_li, self.non_num_preds_type, self.non_num_preds_enc = \\\n",
    "                            all_non_num_predicate_attrs(self.table_dict)\n",
    "        except Exception as e:\n",
    "            raise Exception(f'Failed During Non-Numerical Predicate Parsing:\\n{e}')\n",
    "        if verbose:\n",
    "            print('Non-Numerical Predicate Space:')\n",
    "            print(self.non_num_preds_li)\n",
    "            print('')\n",
    "        return\n",
    "    \n",
    "    def run_query(self,full_flat_query):\n",
    "        full_flat_query = np.array(full_flat_query).flatten() #Just in case\n",
    "        table_enc = full_flat_query[:len(self.table_attrs_enc)]\n",
    "        join_enc = full_flat_query[len(self.table_attrs_enc):\\\n",
    "                                len(self.table_attrs_enc)+\\\n",
    "                                len(self.join_attrs_enc)]\n",
    "        num_preds_enc = full_flat_query[len(self.table_attrs_enc)+\\\n",
    "                                len(self.join_attrs_enc):\\\n",
    "                                len(full_flat_query)-\\\n",
    "                                self.non_num_predicate_lim*len(self.non_num_preds_enc)]\n",
    "        non_num_preds_enc = full_flat_query[len(full_flat_query)-\\\n",
    "                                self.non_num_predicate_lim*len(self.non_num_preds_enc):]\n",
    "        \n",
    "        joins_select = np.nonzero(join_enc)[0].tolist()\n",
    "        #Merging procedure based on joining routine\n",
    "        res_df = pd.DataFrame()\n",
    "        for i in joins_select:\n",
    "            t = self.join_attrs_li[i].split('.')\n",
    "            table_1 = t[0].replace('join-attr-','')\n",
    "            table_2 = t[1].split('-')[-1]\n",
    "            sel_attr = t[-1]\n",
    "            if len(res_df)==0:\n",
    "                res_df = pd.merge(self.table_dict[table_1],\\\n",
    "                                  self.table_dict[table_2],\\\n",
    "                                  how='outer',on=[sel_attr])\n",
    "            else:\n",
    "                res_df = res_df.merge(pd.merge(self.table_dict[table_1],\\\n",
    "                                  self.table_dict[table_2],\\\n",
    "                                  how='outer',on=[sel_attr]))\n",
    "        full_len = len(res_df)\n",
    "        if len(res_df)==0:\n",
    "            return 0,full_len\n",
    "        #Drop any redundant columns that failed on matching\n",
    "        off_cols = [i for i in res_df.columns.tolist() \\\n",
    "                                        if '_x' in i or '_y' in i]\n",
    "        for i in off_cols:\n",
    "            res_df[i.split('_')[0]]=res_df[i]\n",
    "            res_df = res_df.drop(columns=[i])\n",
    "        \n",
    "        #Done with joins, moving to numerical predicates\n",
    "        for i in np.array_split(num_preds_enc,self.num_predicate_lim):\n",
    "            if np.sum(i)!=0: #Check to make sure we have a valid predicate\n",
    "                if len(res_df)==0:\n",
    "                    return 0,full_len\n",
    "                pred_col = np.nonzero(i[:-1])[0][0]\n",
    "                pred_op = np.nonzero(i[:-1])[0][1]\n",
    "                pred_val = i[-1]\n",
    "                t_col = self.num_preds_li[pred_col].split('.')[1]\n",
    "                if res_df[t_col].dtype.char == '?':\n",
    "                    v_min=0\n",
    "                    v_max=1\n",
    "                else:\n",
    "                    v_min = np.min(res_df[t_col].tolist())\n",
    "                    v_max = np.max(res_df[t_col].tolist())\n",
    "                pred_val_scaled = (pred_val*(v_max-v_min))+v_min\n",
    "                if self.num_preds_li[pred_op]=='<':\n",
    "                    res_df = res_df.loc[res_df[t_col]<pred_val_scaled]\n",
    "                elif self.num_preds_li[pred_op]=='>':\n",
    "                    res_df = res_df.loc[res_df[t_col]>pred_val_scaled]\n",
    "                else:\n",
    "                    res_df = res_df.loc[res_df[t_col]==pred_val_scaled]\n",
    "        \n",
    "        #Done with numerical predicates, now on to non-numerical predicates\n",
    "        for i in np.array_split(non_num_preds_enc,self.non_num_predicate_lim):\n",
    "            if np.sum(i)!=0: #Check to make sure we have a valid predicate\n",
    "                pred_col = np.nonzero(i[:-2])[0][0]\n",
    "                pred_val = int(i[-2]*(10**8))\n",
    "                e_ball = i[-1]\n",
    "                t_col = self.non_num_preds_li[pred_col].split('.')[1]\n",
    "                #hash_it = [int(str_hash_procedure(j)*(10**8)) for \\\n",
    "                #           j in res_df[t_col].tolist()]\n",
    "                hash_it = [int(self.string_embedding(j)*(10**8)) for \\\n",
    "                           j in res_df[t_col].tolist()]\n",
    "                res_df = res_df.loc[self.string_dist_func(np.array(hash_it),\\\n",
    "                                                    pred_val)<=e_ball] #ADD E_BALL?\n",
    "                str_L1_distance\n",
    "        return len(res_df),full_len\n",
    "        \n",
    "    \n",
    "    def generate_random_query(self,flatten=True):\n",
    "        num_joins = np.random.choice(range(1,self.join_lim+1))\n",
    "        joins_select = []\n",
    "        while len(joins_select)!=num_joins:\n",
    "            #Note that there's some cleverness about chosing join\n",
    "            #statements that do not automatically conflict with one another.\n",
    "            joins_select = rand_select_joins(self.join_attrs_li,num_joins)\n",
    "        \n",
    "        \n",
    "        #Embedding one-hot enc for join operations\n",
    "        new_join_enc = self.join_attrs_enc.copy()\n",
    "        for i in joins_select:\n",
    "            new_join_enc[i]=1\n",
    "        \n",
    "        \n",
    "        #Embedding one-hot enc for table operators, based on join commands\n",
    "        new_table_enc = self.table_attrs_enc.copy()\n",
    "        all_tables_li = []\n",
    "        for i in joins_select:\n",
    "            t = self.join_attrs_li[i].split('.')\n",
    "            table_1 = t[0].replace('join-attr-','')\n",
    "            table_2 = t[1].split('-')[-1]\n",
    "            all_tables_li+=[table_1,table_2]\n",
    "        all_tables_li = sorted(list(set(all_tables_li)))\n",
    "        for i in all_tables_li:\n",
    "            new_table_enc[self.table_attrs_li.tolist().index(i)]=1\n",
    "        \n",
    "        \n",
    "        #Embedding for numerical predicates (int, float, bool)\n",
    "        all_poss_num_attrs = []\n",
    "        for i in all_tables_li:\n",
    "            c = self.table_dict[i].columns\n",
    "            for j in c:\n",
    "                if f'{i}.{j}' in self.num_preds_li:\n",
    "                    all_poss_num_attrs.append(self.num_preds_li.tolist(\n",
    "                                                    ).index(f'{i}.{j}'))\n",
    "        num_predicates = np.random.choice(range(1,self.num_predicate_lim+1))\n",
    "        new_num_predicates_enc = []\n",
    "        for i in range(num_predicates):\n",
    "            new_num_pred_enc = self.num_preds_enc.copy()\n",
    "            attr_choice = np.random.choice(all_poss_num_attrs,1)[0]\n",
    "            new_num_pred_enc[attr_choice]=1\n",
    "            if self.num_preds_type[attr_choice].char == '?': #? --> BOOL, use =\n",
    "                eq_choice = '='\n",
    "                val_choice = np.random.choice([0,1],1)[0]\n",
    "            elif self.num_preds_type[attr_choice].char == 'l': #l --> INT, USE ANY\n",
    "                eq_choice = np.random.choice(['<','>','='],1)[0]\n",
    "                val_choice = np.random.uniform(0,1,1)[0]\n",
    "            else: #d --> FLOAT, USE < or >\n",
    "                eq_choice = np.random.choice(['<','>'],1)[0]\n",
    "                val_choice = np.random.uniform(0,1,1)[0]\n",
    "            new_num_pred_enc[self.num_preds_li.tolist().index(eq_choice)]=1\n",
    "            new_num_pred_enc[-1]=val_choice\n",
    "            new_num_predicates_enc+=new_num_pred_enc.tolist() #FILL WITH BLANKS!\n",
    "        new_num_predicates_enc+=np.zeros((self.num_predicate_lim-\\\n",
    "                                num_predicates)*len(self.num_preds_enc)).tolist()\n",
    "        \n",
    "        \n",
    "        #Embedding for non-numerical predicates (strings)\n",
    "        all_poss_str_attrs = []\n",
    "        for i in all_tables_li:\n",
    "            c = self.table_dict[i].columns\n",
    "            for j in c:\n",
    "                if f'{i}.{j}' in self.non_num_preds_li:\n",
    "                    all_poss_str_attrs.append(self.non_num_preds_li.tolist(\n",
    "                                                    ).index(f'{i}.{j}'))\n",
    "        if len(all_poss_str_attrs)!=0:\n",
    "            num_str_predicates = np.random.choice(range(1,self.non_num_predicate_lim+1))\n",
    "            new_str_predicates_enc = []\n",
    "            for i in range(num_str_predicates):\n",
    "                new_str_pred_enc = self.non_num_preds_enc.copy()\n",
    "                attr_choice = np.random.choice(all_poss_str_attrs,1)[0]\n",
    "                attr_table = self.non_num_preds_li[attr_choice].split('.')[0]\n",
    "                attr_col = self.non_num_preds_li[attr_choice].split('.')[1]\n",
    "                str_c = np.random.choice(self.table_dict[attr_table]\\\n",
    "                                              [attr_col].tolist(),1)[0]\n",
    "                new_str_pred_enc[attr_choice]=1\n",
    "                #TRY OTHER METHODS OF HASHING AT SOME OTHER POINT, MORE SENSIBLE!\n",
    "                float_c = str_hash_procedure(str_c)\n",
    "                new_str_pred_enc[-2] = float_c\n",
    "                #DON'T MESS WITH THE E-BALL FOR NOW EITHER! KEEP IT AT 0 (perfect match)\n",
    "                new_str_predicates_enc+=new_str_pred_enc.tolist()\n",
    "        \n",
    "            new_str_predicates_enc+=np.zeros((self.non_num_predicate_lim-\\\n",
    "                                    num_str_predicates)*\\\n",
    "                                    len(self.non_num_preds_enc)).tolist()\n",
    "        else:\n",
    "            new_str_predicates_enc=np.zeros(len(self.non_num_preds_enc)*\\\n",
    "                                            self.non_num_predicate_lim)\n",
    "        \n",
    "        \n",
    "        \n",
    "        final_query = [np.array(new_table_enc),np.array(new_join_enc),\\\n",
    "            np.array(new_num_predicates_enc),np.array(new_str_predicates_enc)]\n",
    "        \n",
    "        final_query_flat = np.concatenate((new_table_enc,new_join_enc,\\\n",
    "              new_num_predicates_enc,new_str_predicates_enc))\n",
    "        final_card,full_len = self.run_query(final_query_flat)\n",
    "        \n",
    "        if flatten:\n",
    "            return final_query_flat, final_card/float(full_len)\n",
    "        else:\n",
    "            return final_query, final_card/float(full_len)\n",
    "    \n",
    "    def generate_N_queries(self,n,flatten=True):\n",
    "        all_queries = []\n",
    "        all_card_fracs = []\n",
    "        for i in range(n):\n",
    "            query, frac = self.generate_random_query(flatten)\n",
    "            all_queries.append(query)\n",
    "            all_card_fracs.append(frac)\n",
    "        return np.array(all_queries), np.array(all_card_fracs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_test = Card_Dataset()\n",
    "for i in tables_dict.keys():\n",
    "    card_test.add_table(tables_dict[i],name=str(i))\n",
    "\n",
    "\n",
    "card_test.featurize_space(verbose=False)\n",
    "X, y = card_test.generate_N_queries(50,flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0., 1., 1., 0., 1.])\n",
      " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0.])\n",
      " array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 1.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 1.        ,\n",
      "       0.        , 0.24709005, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        ])\n",
      " array([0., 0., 0., 0., 0., 0., 0., 0.])]\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
